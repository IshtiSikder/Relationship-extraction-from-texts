{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RelationshipExtractor.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/IshtiSikder/Relationship-extraction-from-texts/blob/main/RelationshipExtractor.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "# Kindly select Runtime > Run all from above to run all the following cells successively, and please read the numbered text cells with the code cells below for detailed descriptions about how the code works. \n",
        "\n",
        "\n",
        "\n",
        "# 1. Let's first install some necessary modules/dependencies to build our relation extraction pipeline with python"
      ],
      "metadata": {
        "id": "P6vKsGnnVPmt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install spacy==2.1.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Zj_H1AtFV79",
        "outputId": "f9047df0-f226-43d9-85b4-3412ffc918f9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting spacy==2.1.0\n",
            "  Downloading spacy-2.1.0-cp37-cp37m-manylinux1_x86_64.whl (27.7 MB)\n",
            "\u001b[K     |████████████████████████████████| 27.7 MB 37.9 MB/s \n",
            "\u001b[?25hCollecting thinc<7.1.0,>=7.0.2\n",
            "  Downloading thinc-7.0.8-cp37-cp37m-manylinux1_x86_64.whl (2.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.1 MB 29.6 MB/s \n",
            "\u001b[?25hCollecting blis<0.3.0,>=0.2.2\n",
            "  Downloading blis-0.2.4-cp37-cp37m-manylinux1_x86_64.whl (3.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.2 MB 41.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (2.6.0)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (0.8.2)\n",
            "Collecting preshed<2.1.0,>=2.0.1\n",
            "  Downloading preshed-2.0.1-cp37-cp37m-manylinux1_x86_64.whl (82 kB)\n",
            "\u001b[K     |████████████████████████████████| 82 kB 191 kB/s \n",
            "\u001b[?25hRequirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (2.0.6)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (1.0.5)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (2.23.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (1.0.6)\n",
            "Collecting plac<1.0.0,>=0.9.6\n",
            "  Downloading plac-0.9.6-py2.py3-none-any.whl (20 kB)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy==2.1.0) (1.19.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy==2.1.0) (2021.10.8)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy==2.1.0) (4.62.3)\n",
            "Installing collected packages: preshed, plac, blis, thinc, spacy\n",
            "  Attempting uninstall: preshed\n",
            "    Found existing installation: preshed 3.0.6\n",
            "    Uninstalling preshed-3.0.6:\n",
            "      Successfully uninstalled preshed-3.0.6\n",
            "  Attempting uninstall: plac\n",
            "    Found existing installation: plac 1.1.3\n",
            "    Uninstalling plac-1.1.3:\n",
            "      Successfully uninstalled plac-1.1.3\n",
            "  Attempting uninstall: blis\n",
            "    Found existing installation: blis 0.4.1\n",
            "    Uninstalling blis-0.4.1:\n",
            "      Successfully uninstalled blis-0.4.1\n",
            "  Attempting uninstall: thinc\n",
            "    Found existing installation: thinc 7.4.0\n",
            "    Uninstalling thinc-7.4.0:\n",
            "      Successfully uninstalled thinc-7.4.0\n",
            "  Attempting uninstall: spacy\n",
            "    Found existing installation: spacy 2.2.4\n",
            "    Uninstalling spacy-2.2.4:\n",
            "      Successfully uninstalled spacy-2.2.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "en-core-web-sm 2.2.5 requires spacy>=2.2.2, but you have spacy 2.1.0 which is incompatible.\u001b[0m\n",
            "Successfully installed blis-0.2.4 plac-0.9.6 preshed-2.0.1 spacy-2.1.0 thinc-7.0.8\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download en_core_web_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZhLwuoqIs3q",
        "outputId": "57411726-93b2-45b7-df11-b12d5d8ca48b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en_core_web_sm==2.1.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.1.0/en_core_web_sm-2.1.0.tar.gz (11.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 11.1 MB 6.6 MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: en-core-web-sm\n",
            "  Building wheel for en-core-web-sm (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for en-core-web-sm: filename=en_core_web_sm-2.1.0-py3-none-any.whl size=11074431 sha256=18a09e97dc72e660fe1259d8035f86f2df8366c9c2700d9878f33a28417070a3\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-1f1q5a7_/wheels/59/4f/8c/0dbaab09a776d1fa3740e9465078bfd903cc22f3985382b496\n",
            "Successfully built en-core-web-sm\n",
            "Installing collected packages: en-core-web-sm\n",
            "  Attempting uninstall: en-core-web-sm\n",
            "    Found existing installation: en-core-web-sm 2.2.5\n",
            "    Uninstalling en-core-web-sm-2.2.5:\n",
            "      Successfully uninstalled en-core-web-sm-2.2.5\n",
            "Successfully installed en-core-web-sm-2.1.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_sm')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install neuralcoref"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BDh6ELeNHcuo",
        "outputId": "21a17a59-7895-453e-df59-28fc3b83185e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting neuralcoref\n",
            "  Downloading neuralcoref-4.0-cp37-cp37m-manylinux1_x86_64.whl (286 kB)\n",
            "\u001b[K     |████████████████████████████████| 286 kB 5.2 MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "  Downloading boto3-1.20.31-py3-none-any.whl (131 kB)\n",
            "\u001b[K     |████████████████████████████████| 131 kB 46.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.23.0)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (1.19.5)\n",
            "Requirement already satisfied: spacy>=2.1.0 in /usr/local/lib/python3.7/dist-packages (from neuralcoref) (2.1.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->neuralcoref) (2021.10.8)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.6)\n",
            "Requirement already satisfied: plac<1.0.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.9.6)\n",
            "Requirement already satisfied: thinc<7.1.0,>=7.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (7.0.8)\n",
            "Requirement already satisfied: blis<0.3.0,>=0.2.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.2.4)\n",
            "Requirement already satisfied: srsly<1.1.0,>=0.0.5 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.5)\n",
            "Requirement already satisfied: preshed<2.1.0,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.0.1)\n",
            "Requirement already satisfied: wasabi<1.1.0,>=0.0.12 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (0.8.2)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (1.0.6)\n",
            "Requirement already satisfied: jsonschema<3.0.0,>=2.6.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.1.0->neuralcoref) (2.6.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.10.0 in /usr/local/lib/python3.7/dist-packages (from thinc<7.1.0,>=7.0.2->spacy>=2.1.0->neuralcoref) (4.62.3)\n",
            "Collecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading jmespath-0.10.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting s3transfer<0.6.0,>=0.5.0\n",
            "  Downloading s3transfer-0.5.0-py3-none-any.whl (79 kB)\n",
            "\u001b[K     |████████████████████████████████| 79 kB 7.2 MB/s \n",
            "\u001b[?25hCollecting botocore<1.24.0,>=1.23.31\n",
            "  Downloading botocore-1.23.31-py3-none-any.whl (8.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 8.5 MB 47.5 MB/s \n",
            "\u001b[?25hCollecting urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1\n",
            "  Downloading urllib3-1.25.11-py2.py3-none-any.whl (127 kB)\n",
            "\u001b[K     |████████████████████████████████| 127 kB 47.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/dist-packages (from botocore<1.24.0,>=1.23.31->boto3->neuralcoref) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.24.0,>=1.23.31->boto3->neuralcoref) (1.15.0)\n",
            "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3, neuralcoref\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 1.24.3\n",
            "    Uninstalling urllib3-1.24.3:\n",
            "      Successfully uninstalled urllib3-1.24.3\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "Successfully installed boto3-1.20.31 botocore-1.23.31 jmespath-0.10.0 neuralcoref-4.0 s3transfer-0.5.0 urllib3-1.25.11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install folium==0.2.1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lKlW-KqUILWF",
        "outputId": "3b316bde-1b9c-4238-d055-45426d44062d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting folium==0.2.1\n",
            "  Downloading folium-0.2.1.tar.gz (69 kB)\n",
            "\u001b[?25l\r\u001b[K     |████▊                           | 10 kB 25.3 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 20 kB 9.9 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 30 kB 8.8 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 40 kB 8.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 51 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 61 kB 5.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 69 kB 3.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: Jinja2 in /usr/local/lib/python3.7/dist-packages (from folium==0.2.1) (2.11.3)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2->folium==0.2.1) (2.0.1)\n",
            "Building wheels for collected packages: folium\n",
            "  Building wheel for folium (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for folium: filename=folium-0.2.1-py3-none-any.whl size=79809 sha256=0adf8133b20cf5ea37aaa2b4f73d357b22847c7997ce23a3a28f8847f3b25a1d\n",
            "  Stored in directory: /root/.cache/pip/wheels/9a/f0/3a/3f79a6914ff5affaf50cabad60c9f4d565283283c97f0bdccf\n",
            "Successfully built folium\n",
            "Installing collected packages: folium\n",
            "  Attempting uninstall: folium\n",
            "    Found existing installation: folium 0.8.3\n",
            "    Uninstalling folium-0.8.3:\n",
            "      Successfully uninstalled folium-0.8.3\n",
            "Successfully installed folium-0.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Let's now build a **coreference resolution function** using two python modules designated for the task, which are **spacy** and **neuralcoref**. neuralcoref is a production-ready neural network that we will run on one of spacy's annotated english language corpuses (**en_core_web_sm**) to conduct coreference resolution on any given text.\n",
        "\n",
        "# **Coreference resolution** denotes to the task of teaching a machine how to link all the pronouns used in a sentence with related nouns. By establishing the coreferences, the pipeline avoids disambiguation among entities. "
      ],
      "metadata": {
        "id": "tkr9iy5JNSPy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import neuralcoref\n",
        "\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "neuralcoref.add_to_pipe(nlp)\n",
        "\n",
        "def coref_resolution(text):\n",
        "    doc = nlp(text)\n",
        "    tok_list = list(token.text_with_ws for token in doc)\n",
        "    for cluster in doc._.coref_clusters:\n",
        "        cluster_main_words = set(cluster.main.text.split(' '))\n",
        "        for coref in cluster:\n",
        "            if coref != cluster.main:  \n",
        "                if coref.text != cluster.main.text and bool(set(coref.text.split(' ')).intersection(cluster_main_words)) == False:\n",
        "                    tok_list[coref.start] = cluster.main.text + \\\n",
        "                        doc[coref.end-1].whitespace_\n",
        "                    for i in range(coref.start+1, coref.end):\n",
        "                        tok_list[i] = \"\"\n",
        "\n",
        "    return \"\".join(tok_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1g9Aj0ABJZhs",
        "outputId": "ad20ef18-341c-4951-9a64-5ca2a0796486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 40155833/40155833 [00:01<00:00, 32894752.50B/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. We will test our coreference resolution function on an example text. The text is as follows, collected from Wikipedia at random."
      ],
      "metadata": {
        "id": "5i42tIL6WyvA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test = \"Elon Musk is a business magnate, industrial designer, and engineer. He is the founder of SpaceX. He is also early investor, CEO, and product architect of Tesla, Inc. He is also the founder of The Boring Company and the co-founder of Neuralink. Musk was born to a Canadian mother and South African father and raised in Pretoria, South Africa. He briefly attended the University of Pretoria before moving to Canada aged 17 to attend Queen's University. He transferred to the University of Pennsylvania two years later, where he received dual bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University, but decided instead to pursue a business career. He went on co-founding a web software company Zip2 with his brother Kimbal Musk.\""
      ],
      "metadata": {
        "id": "Xo86z0s0KrDP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "oNRnBiupK5Ht",
        "outputId": "eccff023-7130-44bf-9e39-c2318430889d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Elon Musk is a business magnate, industrial designer, and engineer. He is the founder of SpaceX. He is also early investor, CEO, and product architect of Tesla, Inc. He is also the founder of The Boring Company and the co-founder of Neuralink. Musk was born to a Canadian mother and South African father and raised in Pretoria, South Africa. He briefly attended the University of Pretoria before moving to Canada aged 17 to attend Queen's University. He transferred to the University of Pennsylvania two years later, where he received dual bachelor's degrees in economics and physics. He moved to California in 1995 to attend Stanford University, but decided instead to pursue a business career. He went on co-founding a web software company Zip2 with his brother Kimbal Musk.\""
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results = coref_resolution(test)"
      ],
      "metadata": {
        "id": "SNZAXMXPKx_L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. If we compare the original text with the results below, we can see that the coreference resolution function properly replaced all the pronouns in the original text with corresponding nouns. "
      ],
      "metadata": {
        "id": "0mrZEkPkXCC6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "7ub9jnuW_Olr",
        "outputId": "1e34c512-ff81-48c7-ea86-d6e602239300"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"Elon Musk is a business magnate, industrial designer, and engineer. Elon Musk is the founder of SpaceX. Elon Musk is also early investor, CEO, and product architect of Tesla, Inc. Elon Musk is also the founder of The Boring Company and the co-founder of Neuralink. Musk was born to a Canadian mother and South African father and raised in Pretoria, South Africa. Elon Musk briefly attended the University of Pretoria before moving to Canada aged 17 to attend Queen's University. Elon Musk transferred to the University of Pennsylvania two years later, where Elon Musk received dual bachelor's degrees in economics and physics. Elon Musk moved to California in 1995 to attend Stanford University, but decided instead to pursue a business career. Elon Musk went on co-founding a web software company Zip2 with Elon Musk brother Kimbal Musk.\""
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. We will now build a **wikifier** function that can conduct **Named Entity Linking** , which referes to the task of labelling entities in a text based on their general classification (i.e Elon Musk can be labelled as *Person*,Tesla can be labelled as *Organization* etc.). For building the wikifier function, we will use the **wikifier API**. Wikifier is a large database of labelled entities collected from Wikipedia texts. \n",
        "\n",
        "# Considering our text chunk, we will use the wikifier API to cross check their database for three specific labels: Person, Organization and Location. "
      ],
      "metadata": {
        "id": "mjz2kRaOb_y_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import urllib\n",
        "from string import punctuation\n",
        "import nltk\n",
        "import json\n",
        "\n",
        "ENTITY_TYPES = [\"human\", \"person\", \"company\", \"enterprise\", \"business\", \"geographic region\",\n",
        "                \"human settlement\", \"geographic entity\", \"territorial entity type\", \"organization\"]\n",
        "\n",
        "def wikifier(text, lang=\"en\", threshold=0.8):\n",
        "    data = urllib.parse.urlencode([\n",
        "        (\"text\", text), (\"lang\", lang),\n",
        "        (\"userKey\", \"tgbdmkpmkluegqfbawcwjywieevmza\"),\n",
        "        (\"pageRankSqThreshold\", \"%g\" %\n",
        "         threshold), (\"applyPageRankSqThreshold\", \"true\"),\n",
        "        (\"nTopDfValuesToIgnore\", \"100\"), (\"nWordsToIgnoreFromList\", \"100\"),\n",
        "        (\"wikiDataClasses\", \"true\"), (\"wikiDataClassIds\", \"false\"),\n",
        "        (\"support\", \"true\"), (\"ranges\", \"false\"), (\"minLinkFrequency\", \"2\"),\n",
        "        (\"includeCosines\", \"false\"), (\"maxMentionEntropy\", \"3\")\n",
        "    ])\n",
        "    url = \"http://www.wikifier.org/annotate-article\"\n",
        "    req = urllib.request.Request(url, data=data.encode(\"utf8\"), method=\"POST\")\n",
        "    with urllib.request.urlopen(req, timeout=60) as f:\n",
        "        response = f.read()\n",
        "        response = json.loads(response.decode(\"utf8\"))\n",
        "    results = list()\n",
        "    for annotation in response[\"annotations\"]:\n",
        "        if ('wikiDataClasses' in annotation) and (any([el['enLabel'] in ENTITY_TYPES for el in annotation['wikiDataClasses']])):\n",
        "            if any([el['enLabel'] in [\"human\", \"person\"] for el in annotation['wikiDataClasses']]):\n",
        "                label = 'Person'\n",
        "            elif any([el['enLabel'] in [\"company\", \"enterprise\", \"business\", \"organization\"] for el in annotation['wikiDataClasses']]):\n",
        "                label = 'Organization'\n",
        "            elif any([el['enLabel'] in [\"geographic region\", \"human settlement\", \"geographic entity\", \"territorial entity type\"] for el in annotation['wikiDataClasses']]):\n",
        "                label = 'Location'\n",
        "            else:\n",
        "                label = None\n",
        "\n",
        "            results.append({'title': annotation['title'], 'wikiId': annotation['wikiDataItemId'], 'label': label,\n",
        "                            'characters': [(el['chFrom'], el['chTo']) for el in annotation['support']]})\n",
        "    return results"
      ],
      "metadata": {
        "id": "VVnjlEwOLlxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Let's run the cell below to check if the wikifier function is working properly. \n",
        "\n",
        "#We can see that some labels are wrong. For example, South Africa has been labelled as an **organization** whereas it should have been labelled as **location**. \n",
        "\n",
        "# To improve on this, an alternate and more robust module called **Facebook BLINK model** can be used for Named Entity Linking instead of wikifier, which is pretty dated. In this case, Facebook BLINK model hasn't been implemented because of it's extensive memory requirements, which can put a strain on the overall performance of this pipeline given the memory constraints of Google colab. "
      ],
      "metadata": {
        "id": "wLRLzwwjg8Gt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "data = wikifier(results)\n",
        "\n",
        "pd.DataFrame(data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        },
        "id": "lzgS1LIcL-NN",
        "outputId": "493de887-fc33-44f7-b30d-c28945cb22a8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-7bd267e7-3a43-440c-a2de-b5b2b37f2409\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>wikiId</th>\n",
              "      <th>label</th>\n",
              "      <th>characters</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>Q317521</td>\n",
              "      <td>Person</td>\n",
              "      <td>[(0, 8), (5, 8), (68, 76), (73, 76), (104, 112...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>SpaceX</td>\n",
              "      <td>Q193701</td>\n",
              "      <td>Organization</td>\n",
              "      <td>[(96, 101)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Tesla, Inc.</td>\n",
              "      <td>Q478214</td>\n",
              "      <td>Organization</td>\n",
              "      <td>[(168, 172), (168, 177), (168, 178)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Boring Company</td>\n",
              "      <td>Q28874479</td>\n",
              "      <td>Organization</td>\n",
              "      <td>[(213, 230)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>South Africa</td>\n",
              "      <td>Q258</td>\n",
              "      <td>Organization</td>\n",
              "      <td>[(304, 316), (349, 360), (349, 361)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Pretoria</td>\n",
              "      <td>Q3926</td>\n",
              "      <td>Organization</td>\n",
              "      <td>[(339, 346), (339, 360), (408, 415)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>University of Pretoria</td>\n",
              "      <td>Q604444</td>\n",
              "      <td>Organization</td>\n",
              "      <td>[(394, 415)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>University of Pennsylvania</td>\n",
              "      <td>Q49117</td>\n",
              "      <td>Organization</td>\n",
              "      <td>[(504, 533), (508, 533), (522, 533)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Stanford University</td>\n",
              "      <td>Q41506</td>\n",
              "      <td>Organization</td>\n",
              "      <td>[(675, 693)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Zip2</td>\n",
              "      <td>Q28222602</td>\n",
              "      <td>Organization</td>\n",
              "      <td>[(798, 801)]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>Kimbal Musk</td>\n",
              "      <td>Q6409751</td>\n",
              "      <td>Person</td>\n",
              "      <td>[(826, 831), (826, 836)]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7bd267e7-3a43-440c-a2de-b5b2b37f2409')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7bd267e7-3a43-440c-a2de-b5b2b37f2409 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7bd267e7-3a43-440c-a2de-b5b2b37f2409');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                         title  ...                                         characters\n",
              "0                    Elon Musk  ...  [(0, 8), (5, 8), (68, 76), (73, 76), (104, 112...\n",
              "1                       SpaceX  ...                                        [(96, 101)]\n",
              "2                  Tesla, Inc.  ...               [(168, 172), (168, 177), (168, 178)]\n",
              "3           The Boring Company  ...                                       [(213, 230)]\n",
              "4                 South Africa  ...               [(304, 316), (349, 360), (349, 361)]\n",
              "5                     Pretoria  ...               [(339, 346), (339, 360), (408, 415)]\n",
              "6       University of Pretoria  ...                                       [(394, 415)]\n",
              "7   University of Pennsylvania  ...               [(504, 533), (508, 533), (522, 533)]\n",
              "8          Stanford University  ...                                       [(675, 693)]\n",
              "9                         Zip2  ...                                       [(798, 801)]\n",
              "10                 Kimbal Musk  ...                           [(826, 831), (826, 836)]\n",
              "\n",
              "[11 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. We will now clone an open source python module named OpenNRE from Github which can build us our relation extraction model using BERT."
      ],
      "metadata": {
        "id": "uF5qRnmHK34F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/thunlp/OpenNRE.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-PcKD4bqZcuN",
        "outputId": "7970ed09-49ba-41e5-ff05-b122e0c59188"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'OpenNRE'...\n",
            "remote: Enumerating objects: 1514, done.\u001b[K\n",
            "remote: Counting objects: 100% (137/137), done.\u001b[K\n",
            "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
            "remote: Total 1514 (delta 81), reused 82 (delta 42), pack-reused 1377\u001b[K\n",
            "Receiving objects: 100% (1514/1514), 266.83 MiB | 28.97 MiB/s, done.\n",
            "Resolving deltas: 100% (901/901), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Changing Google colab directory to fetch requirements.txt file imported from the github repo of OpenNRE. We will use this .txt file to install necessary modules/dependencies to build the relation extraction model"
      ],
      "metadata": {
        "id": "WYHpso_KLYcN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "cd /content/OpenNRE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnlJACgxgl1M",
        "outputId": "cce42388-f774-43a5-f721-55c61d576276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/OpenNRE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m pip install -r requirements.txt\n",
        "!pip install torch==1.10.0\n",
        "!pip install scikit-learn==0.24"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nsY6ZJhKd6QV",
        "outputId": "bfefeb5f-acc4-45c9-8176-405c06afcff3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch==1.6.0\n",
            "  Downloading torch-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (748.8 MB)\n",
            "\u001b[K     |████████████████████████████████| 748.8 MB 19 kB/s \n",
            "\u001b[?25hCollecting transformers==3.4.0\n",
            "  Downloading transformers-3.4.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 38.7 MB/s \n",
            "\u001b[?25hCollecting pytest==5.3.2\n",
            "  Downloading pytest-5.3.2-py3-none-any.whl (234 kB)\n",
            "\u001b[K     |████████████████████████████████| 234 kB 51.9 MB/s \n",
            "\u001b[?25hCollecting scikit-learn==0.22.1\n",
            "  Downloading scikit_learn-0.22.1-cp37-cp37m-manylinux1_x86_64.whl (7.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 7.0 MB 23.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy==1.4.1 in /usr/local/lib/python3.7/dist-packages (from -r requirements.txt (line 5)) (1.4.1)\n",
            "Collecting nltk>=3.6.4\n",
            "  Downloading nltk-3.6.7-py3-none-any.whl (1.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5 MB 36.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0->-r requirements.txt (line 1)) (1.19.5)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.17.3)\n",
            "Collecting tokenizers==0.9.2\n",
            "  Downloading tokenizers-0.9.2-cp37-cp37m-manylinux1_x86_64.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 44.6 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (3.4.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (4.62.3)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 546 kB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3.4.0->-r requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: importlib-metadata>=0.12 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (4.8.2)\n",
            "Requirement already satisfied: attrs>=17.4.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (21.2.0)\n",
            "Requirement already satisfied: py>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (1.11.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (0.2.5)\n",
            "Requirement already satisfied: more-itertools>=4.0.0 in /usr/local/lib/python3.7/dist-packages (from pytest==5.3.2->-r requirements.txt (line 3)) (8.12.0)\n",
            "Collecting pluggy<1.0,>=0.12\n",
            "  Downloading pluggy-0.13.1-py2.py3-none-any.whl (18 kB)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.22.1->-r requirements.txt (line 4)) (1.1.0)\n",
            "Collecting regex!=2019.12.17\n",
            "  Downloading regex-2021.11.10-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (749 kB)\n",
            "\u001b[K     |████████████████████████████████| 749 kB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from nltk>=3.6.4->-r requirements.txt (line 6)) (7.1.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (3.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.12->pytest==5.3.2->-r requirements.txt (line 3)) (3.10.0.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.6)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf->transformers==3.4.0->-r requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3.4.0->-r requirements.txt (line 2)) (1.25.11)\n",
            "Installing collected packages: regex, tokenizers, sentencepiece, sacremoses, pluggy, transformers, torch, scikit-learn, pytest, nltk\n",
            "  Attempting uninstall: regex\n",
            "    Found existing installation: regex 2019.12.20\n",
            "    Uninstalling regex-2019.12.20:\n",
            "      Successfully uninstalled regex-2019.12.20\n",
            "  Attempting uninstall: pluggy\n",
            "    Found existing installation: pluggy 0.7.1\n",
            "    Uninstalling pluggy-0.7.1:\n",
            "      Successfully uninstalled pluggy-0.7.1\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.10.0+cu111\n",
            "    Uninstalling torch-1.10.0+cu111:\n",
            "      Successfully uninstalled torch-1.10.0+cu111\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.0.1\n",
            "    Uninstalling scikit-learn-1.0.1:\n",
            "      Successfully uninstalled scikit-learn-1.0.1\n",
            "  Attempting uninstall: pytest\n",
            "    Found existing installation: pytest 3.6.4\n",
            "    Uninstalling pytest-3.6.4:\n",
            "      Successfully uninstalled pytest-3.6.4\n",
            "  Attempting uninstall: nltk\n",
            "    Found existing installation: nltk 3.2.5\n",
            "    Uninstalling nltk-3.2.5:\n",
            "      Successfully uninstalled nltk-3.2.5\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchvision 0.11.1+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchtext 0.11.0 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "torchaudio 0.10.0+cu111 requires torch==1.10.0, but you have torch 1.6.0 which is incompatible.\n",
            "imbalanced-learn 0.8.1 requires scikit-learn>=0.24, but you have scikit-learn 0.22.1 which is incompatible.\u001b[0m\n",
            "Successfully installed nltk-3.6.7 pluggy-0.13.1 pytest-5.3.2 regex-2021.11.10 sacremoses-0.0.46 scikit-learn-0.22.1 sentencepiece-0.1.96 tokenizers-0.9.2 torch-1.6.0 transformers-3.4.0\n",
            "Collecting torch==1.10.0\n",
            "  Downloading torch-1.10.0-cp37-cp37m-manylinux1_x86_64.whl (881.9 MB)\n",
            "\u001b[K     |██████████████████████████████▎ | 834.1 MB 1.3 MB/s eta 0:00:36tcmalloc: large alloc 1147494400 bytes == 0x55b3bea78000 @  0x7fd40be87615 0x55b384c2e4cc 0x55b384d0e47a 0x55b384c312ed 0x55b384d22e1d 0x55b384ca4e99 0x55b384c9f9ee 0x55b384c32bda 0x55b384ca4d00 0x55b384c9f9ee 0x55b384c32bda 0x55b384ca1737 0x55b384d23c66 0x55b384ca0daf 0x55b384d23c66 0x55b384ca0daf 0x55b384d23c66 0x55b384ca0daf 0x55b384c33039 0x55b384c76409 0x55b384c31c52 0x55b384ca4c25 0x55b384c9f9ee 0x55b384c32bda 0x55b384ca1737 0x55b384c9f9ee 0x55b384c32bda 0x55b384ca0915 0x55b384c32afa 0x55b384ca0c0d 0x55b384c9f9ee\n",
            "\u001b[K     |████████████████████████████████| 881.9 MB 20 kB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch==1.10.0) (3.10.0.2)\n",
            "Installing collected packages: torch\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.6.0\n",
            "    Uninstalling torch-1.6.0:\n",
            "      Successfully uninstalled torch-1.6.0\n",
            "Successfully installed torch-1.10.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "torch"
                ]
              }
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-learn==0.24\n",
            "  Downloading scikit_learn-0.24.0-cp37-cp37m-manylinux2010_x86_64.whl (22.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 22.3 MB 764 kB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.1.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (3.0.0)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.19.5)\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.7/dist-packages (from scikit-learn==0.24) (1.4.1)\n",
            "Installing collected packages: scikit-learn\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 0.22.1\n",
            "    Uninstalling scikit-learn-0.22.1:\n",
            "      Successfully uninstalled scikit-learn-0.22.1\n",
            "Successfully installed scikit-learn-0.24.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "sklearn"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. We can now build the relation extraction model. We will use a pre-trained BERT model from OpenNRE called wiki80_bert_softmax, which can infer 80 different relation types."
      ],
      "metadata": {
        "id": "mtWksCArLwb2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import opennre\n",
        "relation_model = opennre.get_model('wiki80_bert_softmax')\n",
        "relation_model = relation_model.cuda()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5oTb_VyhfYV",
        "outputId": "7522bcd1-1ee6-4a0f-9208-d27c1beb5707"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "2022-01-09 13:47:28,076 - root - INFO - Loading BERT pre-trained checkpoint.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Finally, we will feed our original text to the relation model one sentence at a time. The sentence will first be stripped of all punctuations for ease of analysis, before it's processed by the wikifier function to extract all it's entities. For sentences with 2 or more discernible entities,  permutations of said entities will be sent through the relation model to calculate possible relationships between any 2 entities and confidence levels of said relationships. We will choose the relationship with the highest confidence interval and assign it to the entity pair in question."
      ],
      "metadata": {
        "id": "wu4ZrKAIMaZd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "import string\n",
        "relations_list = []\n",
        "for sentence in results.split(\".\"):\n",
        "  sentence = sentence.translate(str.maketrans('', '', string.punctuation))\n",
        "  entities = wikifier(sentence)\n",
        "  print('entities:',entities)\n",
        "  for permutation in itertools.permutations(entities, 2):\n",
        "    dic = {}\n",
        "    for source in permutation[0]['characters']:\n",
        "      for target in permutation[1]['characters']:\n",
        "        data = relation_model.infer({'text': sentence, 'h': {'pos': [source[0], source[1] + 1]}, 't': {'pos': [target[0], target[1] + 1]}})\n",
        "        dic[data[0]] = data[1]\n",
        "    relations_list.append({'source': permutation[0]['title'], 'target': permutation[1]['title'], 'type': max(dic)})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MqhExsn621B5",
        "outputId": "ada4a90f-cc09-410e-b4e1-82b3cbbc717d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "entities: [{'title': 'Elon Musk', 'wikiId': 'Q317521', 'label': 'Person', 'characters': [(0, 8), (5, 8)]}]\n",
            "entities: [{'title': 'Elon Musk', 'wikiId': 'Q317521', 'label': 'Person', 'characters': [(1, 9), (6, 9)]}]\n",
            "entities: [{'title': 'Elon Musk', 'wikiId': 'Q317521', 'label': 'Person', 'characters': [(1, 9), (6, 9)]}, {'title': 'Tesla, Inc.', 'wikiId': 'Q478214', 'label': 'Organization', 'characters': [(63, 67), (63, 71)]}]\n",
            "entities: [{'title': 'Elon Musk', 'wikiId': 'Q317521', 'label': 'Person', 'characters': [(1, 9), (6, 9)]}, {'title': 'The Boring Company', 'wikiId': 'Q28874479', 'label': 'Organization', 'characters': [(34, 51)]}, {'title': 'Neuralink', 'wikiId': 'Q29043471', 'label': 'Organization', 'characters': [(74, 82)]}]\n",
            "entities: [{'title': 'Pretoria', 'wikiId': 'Q3926', 'label': 'Organization', 'characters': [(75, 82)]}]\n",
            "entities: [{'title': 'Elon Musk', 'wikiId': 'Q317521', 'label': 'Person', 'characters': [(1, 9), (6, 9)]}, {'title': 'University of Pretoria', 'wikiId': 'Q604444', 'label': 'Organization', 'characters': [(32, 53)]}, {'title': 'Pretoria', 'wikiId': 'Q3926', 'label': 'Organization', 'characters': [(46, 53)]}]\n",
            "entities: [{'title': 'Elon Musk', 'wikiId': 'Q317521', 'label': 'Person', 'characters': [(1, 9), (6, 9), (79, 87), (84, 87)]}, {'title': 'University of Pennsylvania', 'wikiId': 'Q49117', 'label': 'Organization', 'characters': [(26, 55), (30, 55), (44, 55)]}]\n",
            "entities: [{'title': 'Elon Musk', 'wikiId': 'Q317521', 'label': 'Person', 'characters': [(1, 9), (6, 9)]}, {'title': 'Stanford University', 'wikiId': 'Q41506', 'label': 'Organization', 'characters': [(49, 67)]}]\n",
            "entities: [{'title': 'Elon Musk', 'wikiId': 'Q317521', 'label': 'Person', 'characters': [(1, 9), (6, 9), (63, 71), (68, 71), (88, 91)]}, {'title': 'Kimbal Musk', 'wikiId': 'Q6409751', 'label': 'Person', 'characters': [(81, 86), (81, 91)]}]\n",
            "entities: []\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Let's now check the final results by running the cell below. The \"type\" column defines the relationship between same row words in the \"source\" and \"target\" columns.\n",
        "\n",
        "# We can see that while most of the defined relationships are apparently logical, there are some mislabellings. i.e Stanford University is not Elon Musk's residence as suggested by rows 16 and 17. Also, One entity seen during only Named Entity Linking, which is Zip2, is missing while doing Named Entity Linking for Relation Extraction. These currently represent some unreliability/limitations for the pipeline and can be fixed by **joint extraction**. In joint extraction, Named Entity Linking and Relation Extraction are conducted simultaneously as opposed to consecutively like we did in this implementation.Joint extraction can be done in various ways (i.e through Integer Programming) but would require us to vastly change the current design of our pipeline."
      ],
      "metadata": {
        "id": "Kvff6GdbQc7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(relations_list)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 677
        },
        "id": "w9kLbccIxjXx",
        "outputId": "7df75405-9708-47a9-acaa-8c3f2645fb06"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-b8508bd2-75f8-4c32-bd40-11d30bf0aea9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>source</th>\n",
              "      <th>target</th>\n",
              "      <th>type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>Tesla, Inc.</td>\n",
              "      <td>owned by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Tesla, Inc.</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>owned by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>The Boring Company</td>\n",
              "      <td>owned by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>Neuralink</td>\n",
              "      <td>owned by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Boring Company</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>owned by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>The Boring Company</td>\n",
              "      <td>Neuralink</td>\n",
              "      <td>subsidiary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Neuralink</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>owned by</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Neuralink</td>\n",
              "      <td>The Boring Company</td>\n",
              "      <td>subsidiary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>University of Pretoria</td>\n",
              "      <td>work location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>Pretoria</td>\n",
              "      <td>work location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>University of Pretoria</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>part of</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>University of Pretoria</td>\n",
              "      <td>Pretoria</td>\n",
              "      <td>subsidiary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>Pretoria</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>residence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>Pretoria</td>\n",
              "      <td>University of Pretoria</td>\n",
              "      <td>has part</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>University of Pennsylvania</td>\n",
              "      <td>work location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>University of Pennsylvania</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>work location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>Stanford University</td>\n",
              "      <td>residence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>Stanford University</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>residence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>Kimbal Musk</td>\n",
              "      <td>sibling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Kimbal Musk</td>\n",
              "      <td>Elon Musk</td>\n",
              "      <td>sibling</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b8508bd2-75f8-4c32-bd40-11d30bf0aea9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b8508bd2-75f8-4c32-bd40-11d30bf0aea9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b8508bd2-75f8-4c32-bd40-11d30bf0aea9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                        source                      target           type\n",
              "0                    Elon Musk                 Tesla, Inc.       owned by\n",
              "1                  Tesla, Inc.                   Elon Musk       owned by\n",
              "2                    Elon Musk          The Boring Company       owned by\n",
              "3                    Elon Musk                   Neuralink       owned by\n",
              "4           The Boring Company                   Elon Musk       owned by\n",
              "5           The Boring Company                   Neuralink     subsidiary\n",
              "6                    Neuralink                   Elon Musk       owned by\n",
              "7                    Neuralink          The Boring Company     subsidiary\n",
              "8                    Elon Musk      University of Pretoria  work location\n",
              "9                    Elon Musk                    Pretoria  work location\n",
              "10      University of Pretoria                   Elon Musk        part of\n",
              "11      University of Pretoria                    Pretoria     subsidiary\n",
              "12                    Pretoria                   Elon Musk      residence\n",
              "13                    Pretoria      University of Pretoria       has part\n",
              "14                   Elon Musk  University of Pennsylvania  work location\n",
              "15  University of Pennsylvania                   Elon Musk  work location\n",
              "16                   Elon Musk         Stanford University      residence\n",
              "17         Stanford University                   Elon Musk      residence\n",
              "18                   Elon Musk                 Kimbal Musk        sibling\n",
              "19                 Kimbal Musk                   Elon Musk        sibling"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}